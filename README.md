tms
===

~/.local/lib/python3.8/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py



1. When Denodo disconnects from a data source, will all cached tables related to the datasource be lost?

2. What is the default join type when Left join two dataset, HASH join or NESTED join? 
When using the HASH join type, Denodo always fetch two complete datasets to join, despite limiting the result set

3. Will joining two large data sets cause OOM? 

4. Does denodo able to read/wite iceberg/hudi datalake table?
5. Does denodo able to connect to hive metata server & reading/writing hive ?
6. Does denodo support HA ? 
7. Does denodo able to cache file while reading parquet file? 
